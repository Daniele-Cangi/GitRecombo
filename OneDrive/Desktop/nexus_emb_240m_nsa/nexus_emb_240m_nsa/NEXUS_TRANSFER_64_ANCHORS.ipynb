{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b582a048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìù NEXUS_TRANSFER_64_ANCHORS.ipynb\n",
    "# -------------------------------------------------------------\n",
    "# üöÄ NEXUS Transfer Learning - 64 Anchors Edition\n",
    "# ‚úÖ Checkpoint ogni 2000 steps\n",
    "# ‚úÖ 64 NSA anchors (vs 32 original)\n",
    "# ‚úÖ Analisi anchor specialization post-training\n",
    "# -------------------------------------------------------------\n",
    "# STEP 0: MOUNT GOOGLE DRIVE & SETUP CHECKPOINT DIR\n",
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "CHECKPOINT_DIR = '/content/drive/MyDrive/nexus_checkpoints_64anchors'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print(f\"‚úÖ Google Drive montato! -> {CHECKPOINT_DIR}\")\n",
    "print(\"‚ö†Ô∏è I checkpoint sopravvivono ai disconnect di Colab.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07491831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: SETUP AMBIENTE (Re-eseguibile)\n",
    "!pip -q install torch transformers datasets tqdm sentencepiece accelerate\n",
    "import torch, platform\n",
    "print(f\"Torch: {torch.__version__} | Python: {platform.python_version()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} | VRAM: {torch.cuda.get_device_properties(0).total_memory/1024**3:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No CUDA detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c226a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2: DOWNLOAD MICROSOFT ALLNLI DATASET\n",
    "from datasets import load_dataset\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"üì• Downloading Microsoft AllNLI dataset...\")\n",
    "\n",
    "# Download AllNLI (combines SNLI + MultiNLI)\n",
    "try:\n",
    "    # Load SNLI dataset\n",
    "    snli = load_dataset(\"snli\", split=\"train\")\n",
    "    print(f\"‚úÖ SNLI loaded: {len(snli):,} examples\")\n",
    "    \n",
    "    # Load MultiNLI dataset  \n",
    "    mnli = load_dataset(\"multi_nli\", split=\"train\")\n",
    "    print(f\"‚úÖ MultiNLI loaded: {len(mnli):,} examples\")\n",
    "    \n",
    "    # Filter out examples with label -1 (unlabeled) and combine\n",
    "    all_data = []\n",
    "    \n",
    "    # Process SNLI\n",
    "    for item in tqdm(snli, desc=\"Processing SNLI\"):\n",
    "        if item['label'] != -1:  # Skip unlabeled\n",
    "            all_data.append({\n",
    "                'sentence1': item['premise'],\n",
    "                'sentence2': item['hypothesis'], \n",
    "                'label': ['entailment', 'neutral', 'contradiction'][item['label']]\n",
    "            })\n",
    "    \n",
    "    # Process MultiNLI\n",
    "    for item in tqdm(mnli, desc=\"Processing MultiNLI\"):\n",
    "        if item['label'] != -1:  # Skip unlabeled\n",
    "            all_data.append({\n",
    "                'sentence1': item['premise'],\n",
    "                'sentence2': item['hypothesis'],\n",
    "                'label': ['entailment', 'neutral', 'contradiction'][item['label']]\n",
    "            })\n",
    "    \n",
    "    # Save to JSONL for PairDataset\n",
    "    with open('/content/allnli_pairs.jsonl', 'w') as f:\n",
    "        for item in all_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    \n",
    "    print(f\"‚úÖ AllNLI dataset ready: {len(all_data):,} examples\")\n",
    "    print(f\"üìÅ Saved to: /content/allnli_pairs.jsonl\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error downloading dataset: {e}\")\n",
    "    print(\"üìù Creating minimal demo dataset for testing...\")\n",
    "    \n",
    "    # Fallback demo data with correct format\n",
    "    demo_data = [\n",
    "        {\"sentence1\": \"A person on a horse jumps over a broken down airplane.\", \"sentence2\": \"A person is at a diner, ordering an omelette.\", \"label\": \"contradiction\"},\n",
    "        {\"sentence1\": \"Children smiling and waving at camera\", \"sentence2\": \"They are smiling at a camera\", \"label\": \"entailment\"},\n",
    "        {\"sentence1\": \"A black race car starts up in front of a crowd of people.\", \"sentence2\": \"A man is driving down a lonely road.\", \"label\": \"contradiction\"},\n",
    "        {\"sentence1\": \"Two women are embracing while holding to go packages.\", \"sentence2\": \"Two women are holding packages.\", \"label\": \"entailment\"},\n",
    "        {\"sentence1\": \"A soccer game with multiple males playing.\", \"sentence2\": \"Some men are playing a sport.\", \"label\": \"entailment\"}\n",
    "    ] * 1000  # Repeat for testing\n",
    "    \n",
    "    with open('/content/allnli_pairs.jsonl', 'w') as f:\n",
    "        for item in demo_data:\n",
    "            f.write(json.dumps(item) + '\\n')\n",
    "    \n",
    "    print(f\"‚úÖ Demo dataset created: {len(demo_data):,} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb5230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: MODEL + LOSS DEFINITIONS\n",
    "import torch, torch.nn as nn, torch.nn.functional as F, numpy as np, random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import math, json\n",
    "\n",
    "class NexusTransfer(nn.Module):\n",
    "    def __init__(self, base_model_name='microsoft/mpnet-base', num_topics=3, hash_dim=256, nsa_anchors=64):\n",
    "        super().__init__()\n",
    "        self.base = AutoModel.from_pretrained(base_model_name)\n",
    "        d = self.base.config.hidden_size\n",
    "        self.topic_head = nn.Linear(d, num_topics)\n",
    "        self.hash_proj = nn.Linear(d, hash_dim)\n",
    "        self.anchors = nn.Parameter(torch.randn(nsa_anchors, d))\n",
    "        print(f\"‚úÖ Base {base_model_name} | Params {sum(p.numel() for p in self.parameters()):,}\")\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        out = self.base(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        h = out.last_hidden_state\n",
    "        if attention_mask is not None:\n",
    "            mask = attention_mask.unsqueeze(-1).float()\n",
    "            h = (h * mask).sum(1) / mask.sum(1).clamp(min=1e-9)\n",
    "        else:\n",
    "            h = h.mean(1)\n",
    "        emb = F.normalize(h, dim=-1)\n",
    "        topic_logits = self.topic_head(emb)\n",
    "        hash_emb = torch.tanh(self.hash_proj(emb))\n",
    "        nsa_scores = emb @ self.anchors.T\n",
    "        return emb, topic_logits, hash_emb, nsa_scores\n",
    "\n",
    "class PairDataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        with open(path,'r',encoding='utf-8') as f:\n",
    "            self.data = [json.loads(l) for l in f]\n",
    "        # Map labels to integers for topic classification\n",
    "        self.label_map = {'entailment': 0, 'neutral': 1, 'contradiction': 2}\n",
    "    def __len__(self): return len(self.data)\n",
    "    def __getitem__(self,i): \n",
    "        d = self.data[i]\n",
    "        return d['sentence1'], d['sentence2'], self.label_map[d['label']]\n",
    "\n",
    "def info_nce(a,b,t=0.07):\n",
    "    sim = a @ b.T / t\n",
    "    labels = torch.arange(sim.size(0), device=sim.device)\n",
    "    return (F.cross_entropy(sim, labels) + F.cross_entropy(sim.T, labels)) / 2\n",
    "\n",
    "def matryoshka_loss(a,b,dims,t=0.07):\n",
    "    return sum(info_nce(F.normalize(a[:,:d],dim=-1), F.normalize(b[:,:d],dim=-1), t) for d in dims)/len(dims)\n",
    "\n",
    "def hash_loss(h):\n",
    "    return ((h - h.sign())**2).mean()\n",
    "\n",
    "def spec_loss(scores_a, scores_b):\n",
    "    return 1.0 - (F.normalize(scores_a,dim=-1)*F.normalize(scores_b,dim=-1)).sum(-1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d0db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: INIT MODEL + DATA + OPTIMIZER\n",
    "import torch, time\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Device:', device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/mpnet-base')\n",
    "model = NexusTransfer(nsa_anchors=64).to(device)\n",
    "try:\n",
    "    model = torch.compile(model, mode='max-autotune')\n",
    "    print('torch.compile enabled')\n",
    "except Exception as e:\n",
    "    print('compile skipped:', e)\n",
    "\n",
    "ds = PairDataset('/content/allnli_pairs.jsonl')\n",
    "print(f'Dataset size: {len(ds):,}')\n",
    "\n",
    "BATCH=64; MAX_LEN=128; DIMS=[768,512,384,256,128]; TEMP=0.07\n",
    "\n",
    "def collate(batch):\n",
    "    A,B,T = zip(*batch)\n",
    "    enc_a = tokenizer(list(A), padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "    enc_b = tokenizer(list(B), padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt')\n",
    "    return enc_a['input_ids'], enc_a['attention_mask'], enc_b['input_ids'], enc_b['attention_mask'], torch.tensor(T)\n",
    "\n",
    "dl = DataLoader(ds, batch_size=BATCH, shuffle=True, drop_last=True, collate_fn=collate)\n",
    "\n",
    "base_params = list(model._orig_mod.base.parameters()) if hasattr(model,'_orig_mod') else list(model.base.parameters())\n",
    "heads = [p for n,p in model.named_parameters() if 'base.' not in n]\n",
    "opt = torch.optim.AdamW([\n",
    "    {'params': base_params, 'lr': 2e-5},\n",
    "    {'params': heads, 'lr': 1e-4}\n",
    "], weight_decay=0.01, fused=True)\n",
    "scaler = GradScaler()\n",
    "\n",
    "start_step = 0\n",
    "latest_ptr = f\"{CHECKPOINT_DIR}/latest_checkpoint.txt\"\n",
    "if os.path.exists(latest_ptr):\n",
    "    try:\n",
    "        with open(latest_ptr) as f: ckpt_path = f.read().strip()\n",
    "        ckpt = torch.load(ckpt_path)\n",
    "        state = ckpt['model']\n",
    "        if any(k.startswith('_orig_mod.') for k in state):\n",
    "            state = {k.replace('_orig_mod.',''):v for k,v in state.items()}\n",
    "            (model._orig_mod if hasattr(model,'_orig_mod') else model).load_state_dict(state)\n",
    "        else:\n",
    "            (model._orig_mod if hasattr(model,'_orig_mod') else model).load_state_dict(state)\n",
    "        opt.load_state_dict(ckpt['opt'])\n",
    "        start_step = ckpt['step']\n",
    "        print('Resumed from', ckpt_path, 'step', start_step)\n",
    "    except Exception as e:\n",
    "        print('Resume failed:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b85e94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 5: TRAINING LOOP (checkpoint ogni 2000 step)\n",
    "TOTAL_STEPS = 30000\n",
    "CKPT_INTERVAL = 2000\n",
    "step = start_step\n",
    "model.train(); opt.zero_grad(set_to_none=True)\n",
    "start_time = time.time()\n",
    "for epoch in range(999999):\n",
    "    for a_ids, a_mask, b_ids, b_mask, topics in dl:\n",
    "        a_ids=a_ids.to(device); a_mask=a_mask.to(device); b_ids=b_ids.to(device); b_mask=b_mask.to(device); topics=topics.to(device)\n",
    "        with autocast():\n",
    "            emb_a, logit_a, hash_a, spec_a = model(a_ids, a_mask)\n",
    "            emb_b, logit_b, hash_b, spec_b = model(b_ids, b_mask)\n",
    "            L_main = matryoshka_loss(emb_a, emb_b, DIMS, t=TEMP)\n",
    "            L_topic = 0.03 * F.cross_entropy(logit_a, topics)\n",
    "            L_hash = 0.01 * hash_loss(hash_a)\n",
    "            L_spec = 0.03 * spec_loss(spec_a, spec_b)\n",
    "            loss = L_main + L_topic + L_hash + L_spec\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.unscale_(opt)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "        scaler.step(opt); scaler.update(); opt.zero_grad(set_to_none=True)\n",
    "        step += 1\n",
    "        if step % 100 == 0:\n",
    "            elapsed = (time.time()-start_time)/3600\n",
    "            speed = (step-start_step)/elapsed if elapsed>0 else 0\n",
    "            print(f\"Step {step:,} | Loss {loss.item():.4f} | M {L_main.item():.3f} T {L_topic.item():.3f} H {L_hash.item():.3f} S {L_spec.item():.3f} | {speed:.0f} st/h\")\n",
    "        if step % CKPT_INTERVAL == 0:\n",
    "            raw = model._orig_mod if hasattr(model,'_orig_mod') else model\n",
    "            ckpt_path = f\"{CHECKPOINT_DIR}/ckpt_{step}.pt\"\n",
    "            torch.save({'step': step, 'model': raw.state_dict(), 'opt': opt.state_dict()}, ckpt_path)\n",
    "            with open(f\"{CHECKPOINT_DIR}/latest_checkpoint.txt\",\"w\") as f: f.write(ckpt_path)\n",
    "            print('üíæ Saved', ckpt_path)\n",
    "        if step >= TOTAL_STEPS:\n",
    "            break\n",
    "    if step >= TOTAL_STEPS:\n",
    "        break\n",
    "print('‚úÖ Training complete. Total steps:', step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d093d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: EVALUATION + SIMILARITY TESTS\n",
    "import numpy as np, os, torch\n",
    "latest_ptr = f\"{CHECKPOINT_DIR}/latest_checkpoint.txt\"\n",
    "if not os.path.exists(latest_ptr):\n",
    "    raise FileNotFoundError('No checkpoint to evaluate')\n",
    "with open(latest_ptr) as f: ckpt_path = f.read().strip()\n",
    "ckpt = torch.load(ckpt_path, map_location='cpu')\n",
    "raw = NexusTransfer(nsa_anchors=64).to(device)\n",
    "raw.load_state_dict(ckpt['model'])\n",
    "raw.eval()\n",
    "\n",
    "def embed(texts, batch_size=32):\n",
    "    all_vecs = []\n",
    "    for i in range(0,len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        enc = tokenizer(batch, padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt').to(device)\n",
    "        with torch.no_grad():\n",
    "            emb, *_ = raw(enc['input_ids'], enc.get('attention_mask'))\n",
    "        all_vecs.append(emb.cpu())\n",
    "    return torch.cat(all_vecs).numpy()\n",
    "\n",
    "tests = [\n",
    " (\"Bitcoin reaches new all-time high\",\"BTC price surges\",True),\n",
    " (\"AI is advancing rapidly\",\"Machine learning progresses\",True),\n",
    " (\"The cat sleeps on the sofa\",\"A feline rests\",True),\n",
    " (\"Rome is the capital of Italy\",\"Bitcoin price rises\",False),\n",
    " (\"Pizza is Italian food\",\"Neural networks for AI\",False)\n",
    "]\n",
    "pos, neg = [], []\n",
    "for a,b,is_pos in tests:\n",
    "    va, vb = embed([a])[0], embed([b])[0]\n",
    "    sim = float(np.dot(va,vb))\n",
    "    (pos if is_pos else neg).append(sim)\n",
    "    badge = '‚úÖ' if (sim>0.65 and is_pos) or (sim<0.35 and not is_pos) else '‚ö†Ô∏è'\n",
    "    print(f\"{badge} {a[:32]:32} <> {b[:32]:32} | {sim:.3f}\")\n",
    "print('\\nAverages -> pos:', np.mean(pos), 'neg:', np.mean(neg), 'separation:', np.mean(pos)-np.mean(neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 7: ANCHOR SPECIALIZATION + EXPORT\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "raw.eval()\n",
    "\n",
    "REPORT_TXT = f\"{CHECKPOINT_DIR}/anchor_analysis.txt\"\n",
    "REPORT_CSV = f\"{CHECKPOINT_DIR}/anchor_top.csv\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def analyze_anchors(sample_size=800):\n",
    "    import random\n",
    "    sample_size = min(sample_size, len(ds))\n",
    "    idxs = random.sample(range(len(ds)), sample_size)\n",
    "    activations = {i: [] for i in range(raw.anchors.shape[0])}\n",
    "    for i in tqdm(idxs, desc='Anchors'):\n",
    "        a,b,_ = ds[i]\n",
    "        enc = tokenizer([a], padding=True, truncation=True, max_length=MAX_LEN, return_tensors='pt').to(device)\n",
    "        emb, _, _, scores = raw(enc['input_ids'], enc.get('attention_mask'))\n",
    "        scores = scores[0].cpu().tolist()\n",
    "        for k,s in enumerate(scores):\n",
    "            if len(activations[k]) < 30:  # retain limited examples per anchor\n",
    "                activations[k].append((s,a[:120]))\n",
    "    with open(REPORT_TXT,'w',encoding='utf-8') as f_txt, open(REPORT_CSV,'w',newline='',encoding='utf-8') as f_csv:\n",
    "        writer = csv.writer(f_csv); writer.writerow(['anchor','score','text'])\n",
    "        for anchor, items in activations.items():\n",
    "            items.sort(key=lambda x: x[0], reverse=True)\n",
    "            f_txt.write(f\"\\n==== ANCHOR {anchor} ===\\n\")\n",
    "            for s,t in items[:10]:\n",
    "                f_txt.write(f\"{s:.3f} | {t}\\n\"); writer.writerow([anchor, f\"{s:.3f}\", t])\n",
    "    print('Saved anchor reports:', REPORT_TXT, REPORT_CSV)\n",
    "\n",
    "analyze_anchors()\n",
    "\n",
    "EXPORT_PATH = f\"{CHECKPOINT_DIR}/nexus_64anchors_final.pt\"\n",
    "raw_to_save = raw._orig_mod if hasattr(raw,'_orig_mod') else raw\n",
    "torch.save({'model_state_dict': raw_to_save.state_dict(), 'config': {'base_model':'microsoft/mpnet-base','nsa_anchors':64,'hash_dim':256,'embedding_dim':768,'matryoshka_dims':DIMS}, 'training_steps': step}, EXPORT_PATH)\n",
    "print('Final model exported ->', EXPORT_PATH)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
